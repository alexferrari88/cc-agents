# Agent Workflows & Use Cases

This document outlines the typical workflows and use cases for the Claude Code Agents Collection, showing how different agents work together to automate and enhance software development processes.

## ðŸŽ¯ Core Workflow Patterns

### 1. Complete Feature Development Lifecycle

**Use Case**: Implementing a new feature from conception to production-ready code

**Workflow Steps**:
1. **Planning**: `spec-driven-architect` creates detailed specifications before any code is written
2. **Research** (if needed): `web-research-specialist` gathers current information about technologies or approaches
3. **Complex Decisions**: `decision-coordinator` orchestrates multi-agent decision making for architectural choices
4. **Implementation**: Standard development work
5. **Quality Assurance**: `code-quality-enforcer` ensures code standards, formatting, linting, and type checking
6. **Testing**: `test-maintainer` ensures comprehensive test coverage for new functionality
7. **Documentation**: `docs-sync-checker` updates all documentation to reflect changes

**Example Scenario**:
```
User: "I need to add real-time notifications to our app"
â†’ spec-driven-architect: Creates notification system specification
â†’ decision-coordinator: Evaluates WebSocket vs SSE vs polling approaches
â†’ Development: Implement chosen solution
â†’ code-quality-enforcer: Runs linting, formatting, type checks
â†’ test-maintainer: Adds notification tests
â†’ docs-sync-checker: Updates API docs and CLAUDE.md
```

### 2. Multi-Agent Consensus Decision Making

**Use Case**: Making complex technical decisions that require multiple perspectives

**Workflow Steps**:
1. **Coordination**: `decision-coordinator` analyzes the decision complexity and selects appropriate proposer agents
2. **Parallel Proposal Generation**: Multiple proposer agents generate diverse solutions simultaneously:
   - `pragmatic-proposer`: Practical, proven approaches
   - `quality-proposer`: Maintainable, robust solutions
   - `innovative-proposer`: Creative, breakthrough ideas
   - `efficiency-proposer`: Performance-optimized solutions
   - `risk-aware-proposer`: Safe, defensive approaches
3. **Consensus**: `consensus-judge` evaluates all proposals and selects the optimal solution

**Example Scenario**:
```
Decision: "Choose database architecture for high-traffic analytics system"
â†’ decision-coordinator: Selects efficiency + risk-aware + pragmatic proposers
â†’ efficiency-proposer: Suggests columnar database with caching layer
â†’ risk-aware-proposer: Recommends proven SQL database with read replicas
â†’ pragmatic-proposer: Suggests existing PostgreSQL with partitioning
â†’ consensus-judge: Weighs proposals and selects optimal approach
```

### 3. Code Quality Enforcement Pipeline

**Use Case**: Maintaining consistent code quality across all changes

**Workflow Steps**:
1. **Automated Quality Checks**: `code-quality-enforcer` runs formatting, linting, type checking
2. **Issue Resolution**: Systematic fixing of quality issues
3. **Test Execution**: Running test suites to ensure no regressions
4. **Verification**: Final quality verification

**Example Scenario**:
```
After implementing search filters:
â†’ code-quality-enforcer: Runs ruff format, ruff check, mypy
â†’ Fixes import ordering and type annotations
â†’ Runs pytest suite
â†’ Reports final quality status
```

### 4. Research-Driven Development

**Use Case**: Making informed decisions based on current technology trends and best practices

**Workflow Steps**:
1. **Research**: `web-research-specialist` gathers current information
2. **Decision Making**: `decision-coordinator` uses research to inform technical choices
3. **Implementation**: Development guided by research insights

**Example Scenario**:
```
User: "What's the best approach for implementing OAuth 2.1 in our FastAPI app?"
â†’ web-research-specialist: Researches OAuth 2.1 specifications, FastAPI libraries, security best practices
â†’ decision-coordinator: Evaluates library options based on research
â†’ spec-driven-architect: Creates implementation specification
â†’ Development proceeds with informed choices
```

## ðŸ”„ Specialized Workflow Scenarios

### Architecture & Planning Workflows

#### **Greenfield Project Architecture**
```
Agents: decision-coordinator â†’ innovative + quality + pragmatic proposers
Focus: Breakthrough potential, solid foundations, practical implementation
Use Case: Designing new microservices architecture
```

#### **Legacy System Modernization**
```
Agents: decision-coordinator â†’ pragmatic + risk-aware + quality + efficiency proposers  
Focus: Safe migration, performance improvement, maintainability
Use Case: Migrating monolith to microservices
```

#### **Technology Stack Selection**
```
Agents: web-research-specialist â†’ decision-coordinator â†’ all proposers â†’ consensus-judge
Focus: Current technology assessment, comprehensive evaluation
Use Case: Choosing between React/Vue/Angular for new frontend
```

### Quality Assurance Workflows

#### **Post-Implementation Quality Gate**
```
Sequence: code-quality-enforcer â†’ test-maintainer â†’ docs-sync-checker
Focus: Comprehensive quality verification before code review
Use Case: After implementing complex feature
```

#### **Technical Debt Reduction**
```
Agents: decision-coordinator â†’ quality + efficiency + pragmatic proposers
Focus: Systematic improvement without breaking changes
Use Case: Refactoring legacy codebase
```

### Crisis Response Workflows

#### **Production Issue Resolution**
```
Agents: decision-coordinator â†’ pragmatic + risk-aware + efficiency proposers
Focus: Rapid stabilization, minimal disruption, monitoring
Use Case: Database performance crisis, service outage
```

#### **Security Incident Response**
```
Agents: web-research-specialist â†’ decision-coordinator â†’ risk-aware + pragmatic proposers
Focus: Current threat assessment, safe remediation
Use Case: Vulnerability discovered in dependencies
```

### Research & Discovery Workflows

#### **Technology Evaluation**
```
Sequence: web-research-specialist â†’ decision-coordinator â†’ consensus-judge
Focus: Informed decision making based on current information
Use Case: Evaluating new frameworks, libraries, or tools
```

#### **Best Practices Research**
```
Agents: web-research-specialist â†’ spec-driven-architect
Focus: Implementing current industry standards
Use Case: Implementing CI/CD pipeline, testing strategies
```

## ðŸš€ Agent Activation Patterns

### Proactive Activation
Some agents are designed to activate automatically:

- **decision-coordinator**: Activates for complex technical decisions
- **code-quality-enforcer**: Triggers after significant code changes
- **test-maintainer**: Activates when new features are implemented
- **docs-sync-checker**: Triggers after feature completion

### Explicit Invocation
Other agents work best when explicitly requested:

- **spec-driven-architect**: "Create a spec for this feature"
- **web-research-specialist**: "Research current best practices for..."
- **consensus system**: "Evaluate different approaches for..."

## ðŸŽ¯ Workflow Selection Guide

### Choose **Complete Feature Development** when:
- Implementing new user-facing features
- Adding new API endpoints
- Building new system components

### Choose **Multi-Agent Consensus** when:
- Multiple technical approaches are viable
- Decision affects multiple teams/systems
- High-impact architectural choices
- Technology selection decisions

### Choose **Quality Enforcement** when:
- After any code changes
- Before code reviews
- Preparing for releases
- Maintaining coding standards

### Choose **Research-Driven** when:
- Working with unfamiliar technologies
- Need current industry best practices
- Evaluating new tools or frameworks
- Implementing security or performance optimizations

## ðŸ“Š Workflow Metrics & Success Indicators

### Feature Development Success:
- âœ… Comprehensive specification exists
- âœ… All quality checks pass
- âœ… Test coverage maintained/improved
- âœ… Documentation synchronized

### Decision Making Success:
- âœ… Multiple perspectives considered
- âœ… Trade-offs clearly documented
- âœ… Implementation plan defined
- âœ… Success metrics established

### Quality Enforcement Success:
- âœ… All linting/formatting issues resolved
- âœ… Type checking passes
- âœ… Test suite passes
- âœ… No regressions introduced

## ðŸ”— Integration with Development Tools

These workflows integrate seamlessly with standard development practices:

- **Git workflows**: Agents work with feature branches and pull requests
- **CI/CD pipelines**: Quality enforcement integrates with automated testing
- **Code reviews**: Specifications and quality checks improve review efficiency
- **Documentation systems**: Automatic synchronization reduces maintenance overhead

The agent collection transforms ad-hoc development processes into systematic, repeatable workflows that consistently deliver high-quality results while reducing cognitive load on developers.